# Inspeção de Usabilidade

## Acesso das tabelas (Notion)

### Detecção
- [Arthur Djan Pinheiro Pontes](https://www.notion.so/269f84ef8262807bb3d9c43d954ce977?v=269f84ef8262812e8160000c04bccf59)

- [Pedro Jhevison Menezes de Souza](https://www.notion.so/269f84ef8262801c928ff1844ba276d4?v=269f84ef826281929e99000cf384059e)

- [Jeziel Monteiro Pessoa](https://www.notion.so/269f84ef826280848d2de39d57344a50?v=269f84ef8262813abb2f000c548d5553)

- [Pâmilla Nunes Santos](https://www.notion.so/269f84ef8262806f85d8cc74817deeee?v=269f84ef826281609458000cc3bdd41b)

- [Heloyse Heloá Serrão Viana](https://www.notion.so/269f84ef82628092a96fff7d7b0767c2?v=269f84ef8262812db6cb000c3b6dd952)

- [Sérgio Augusto Limões Da Silva](https://www.notion.so/269f84ef82628049af85f80d575615c2?v=269f84ef826281498ea1000c00ce7eea)

### Coleção
- [](https://www.notion.so/269f84ef82628054b772cbe26a22793c?v=269f84ef826280859d43000c7db81532)
  
## Preparação (Notion)
Para organizar a inspeção, foi definido um integrante do grupo como responsável por criar e manter as tabelas dentro do Notion.  
Foram criados quatro bancos de dados principais para registrar, consolidar e classificar os problemas de usabilidade identificados:

### Detecção Individual
Cada inspetor registrou um problema por vez, de forma independente, sem duplicidade.  
O registro incluiu a localização, a descrição, a evidência (screenshot ou trecho), o inspetor responsável e a heurística violada.

### Coleção Consolidada
Todos os registros foram unificados em uma única tabela.  
Foram removidas duplicatas e mantido o histórico de origem para rastreabilidade.

### Discriminação (Classificação)
Cada problema foi classificado como defeito real ou falso-positivo, conforme análise crítica do grupo.

### Lista Limpa (Relato Final)
Foi produzida uma lista depurada com os problemas confirmados.  
Foram incluídas recomendações de correção, acompanhadas da justificativa sobre a importância de cada ajuste para a experiência do usuário.  
Além disso, foi definida a taxonomia de telas/fluxos que serviram como referência para os inspetores (ex.: Login, Cadastro, Home, Busca, Checkout).

## Etapas Realizadas

### 1. Detecção Individual
Cada integrante navegou pelas telas e fluxos do sistema MIRO.  
Todas as violações de heurísticas de usabilidade foram registradas em tabelas no Notion.  

**Campos registrados incluíram:**
- ID do problema  
- Localização (tela/fluxo)  
- Descrição do problema  
- Evidência (print ou trecho)  
- Inspetor responsável  
- Heurística associada  

### 2. Coleção
Os problemas identificados individualmente foram reunidos em uma coleção única.  
Foi realizado o processo de deduplicação, eliminando registros repetidos.  
O histórico de quem detectou cada problema foi preservado, garantindo rastreabilidade.

### 3. Discriminação
Os problemas foram classificados como:  
- Defeito confirmado (violação real de heurística)  
- Falso-positivo (quando não caracterizava de fato uma falha de usabilidade)  

### 4. Relato dos Resultados
Ao final do processo de inspeção, foi elaborada uma lista limpa contendo apenas os problemas confirmados, ou seja, aqueles que, após a etapa de discriminação, foram reconhecidos como violações reais das heurísticas de usabilidade.  
Cada item dessa lista foi documentado de maneira estruturada, incluindo:

- **Localização:** indicação precisa da tela ou do fluxo em que o problema foi identificado, permitindo que a equipe de desenvolvimento localize facilmente a falha no sistema.  
- **Descrição:** relato detalhado da natureza do problema, explicando como ele ocorre e de que forma prejudica a interação do usuário.  
- **Heurística violada:** identificação do princípio de usabilidade comprometido, fundamentando a gravidade da ocorrência e relacionando-a às diretrizes consolidadas de Nielsen.  
- **Recomendação de correção:** sugestão clara de solução ou ajuste necessário, direcionando a equipe responsável para uma melhoria eficaz.
